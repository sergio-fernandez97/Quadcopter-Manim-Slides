# TODO
1. Correct 01 slide
2. Complete Linearization slide

## Missing slides:
[ ] Structure of the Dissertation
[ ] iLQR slide.
[x] Policy, Value functions: Optimal value and policy
[x] policy for a quadcopter (ANN) and simulation: \mu_\theta, \pi(u_t|x_t) = \mathcal{N}(\mu_\theta(x_t); \boldsymbol{\Sigma})
[x] Model-based vs. Model-free methods: general schema (figure 3.2)
[ ] Guided Policy Search:
    3.1 Problem statement
    3.2 BADAMM
    3.3 brief method derivation
    3.4 Diagram (figure 6.5)
    3.5 Cost shape for quadcopter
    3.6 Present results (Section 6.3.1)
[ ] TD Learning -> DDPG
    4.1 Q-learning: brief derivation, exploration explain algorithm through recycling robot example.
    4.2 DDPG:
        4.2.1 Actor-Crtic: schema (figure 5.1)
        4.2.2 Actor: Deterministic Policy Gradient
        4.2.3 Crtic: Deep Q-learning
        4.2.4 Diagram (figure 6.6)
        4.2.5 Present results (Section 6.3.2)
[ ] Stability Analysis
    5.1 Linear
    5.2 iLQR
    5.3 GPS 
    5.4 DDPG
[ ] Conclusion

https://www.reddit.com/r/manim/comments/1pzpra3/mdps_demo_using_manim/


